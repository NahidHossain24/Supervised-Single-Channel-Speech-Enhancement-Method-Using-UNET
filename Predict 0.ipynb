{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4973b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_tools.ipynb\n",
      "importing Jupyter notebook from args.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "from data_tools import *\n",
    "from args import parser\n",
    "import librosa\n",
    "import os\n",
    "from tensorflow.keras.models import *\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from IPython.lib.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64e5371",
   "metadata": {},
   "outputs": [],
   "source": [
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13463373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to find pre-trained weights / save models\n",
    "voice_weigth_path = args.voice_weigths_folder\n",
    "noise_weigth_path= args.noise_weigths_folder\n",
    "#pre trained model\n",
    "name_model = args.name_model\n",
    "#directory where read noisy sound to denoise\n",
    "audio_dir_prediction = args.audio_dir_prediction\n",
    "#directory to save the denoise sound\n",
    "dir_save_prediction = args.dir_save_prediction\n",
    "#Name noisy sound file to denoise\n",
    "audio_input_prediction = args.audio_input_prediction\n",
    "#Name of denoised sound file to save\n",
    "audio_output_voice_prediction = args.audio_output_voice_prediction\n",
    "audio_output_noise_prediction = args.audio_output_noise_prediction\n",
    "# Sample rate to read audio\n",
    "sample_rate = args.sample_rate\n",
    "# Minimum duration of audio files to consider\n",
    "min_duration = args.min_duration\n",
    "#Frame length for training data\n",
    "frame_length = args.frame_length\n",
    "# hop length for sound files\n",
    "hop_length_frame = frame_length\n",
    "#nb of points for fft(for spectrogram computation)\n",
    "n_fft = args.n_fft\n",
    "#hop length for fft\n",
    "hop_length_fft = args.hop_length_fft\n",
    "SNR= [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e8e06f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(SNR)):\n",
    "    audio_dir_prediction= args.audio_dir_prediction\n",
    "    # load json and create model\n",
    "    json_file = open(voice_weigth_path+'/'+name_model+'= '+str(SNR[k])+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(voice_weigth_path+'/'+name_model+'= '+str(SNR[k])+'.h5')\n",
    "    \n",
    "    #Taking test signals according to the SNR\n",
    "    audio_dir_prediction= new_path(audio_dir_prediction, SNR[k])\n",
    "    \n",
    "    #List the test signals\n",
    "    list_file = os.listdir(audio_dir_prediction)\n",
    "    list_file= sorted_nicely(list_file)\n",
    "    length= len(list_file)\n",
    "    \n",
    "    for i in range(length):\n",
    "        name= os.path.splitext(list_file[i])[0]\n",
    "        audio = audio_files_to_numpy2(audio_dir_prediction, list_file[i], sample_rate,frame_length, hop_length_frame, min_duration)\n",
    "        dim_square_spec = int(n_fft / 2) + 1\n",
    "\n",
    "        complex_mat, real_mat, imag_mat= numpy_audio_to_matrix_spectrogram(audio, dim_square_spec,n_fft, hop_length_fft)\n",
    "        audio_concat= np.concatenate((real_mat, imag_mat))\n",
    "\n",
    "        #global scaling to have distribution -1/1\n",
    "        X_in1 = scaled_in(audio_concat)\n",
    "\n",
    "        #Reshape for prediction\n",
    "        X_in1 = X_in1.reshape(X_in1.shape[0],X_in1.shape[1],X_in1.shape[2],1)\n",
    "\n",
    "        #Prediction using loaded network\n",
    "        X_pred1 = loaded_model.predict(X_in1)\n",
    "\n",
    "        #Rescale back the noise model\n",
    "        inv_sca_X_pred1 = inv_scaled_ou(X_pred1)\n",
    "        X_denoise1 = audio_concat - inv_sca_X_pred1[:,:,:,0]\n",
    "        #X_denoise1 = inv_sca_X_pred1[:,:,:,0]\n",
    "        \n",
    "        l = int(X_denoise1.shape[0]/2)\n",
    "        h= int(X_denoise1.shape[0])\n",
    "\n",
    "        real = X_denoise1[0:l,:,:]\n",
    "        imaginary= X_denoise1[l:h,:,:]\n",
    "\n",
    "        my_complex_matrix= real+ 1j*imaginary\n",
    "        mag, phase= librosa.magphase(my_complex_matrix)\n",
    "\n",
    "        enhanced_speech= matrix_spectrogram_to_numpy_audio(mag, phase, frame_length, hop_length_fft)\n",
    "        nb_samples= enhanced_speech.shape[0]\n",
    "\n",
    "        enhanced_speech_new= enhanced_speech.reshape(1, nb_samples*frame_length)\n",
    "        sf.write('./Evaluation Techniques/composite/Enhanced/'+str(SNR[k])+'/'+name+'Enhanced'+'.wav', enhanced_speech_new[0, :], sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f19b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
