{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1121bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_tools.ipynb\n",
      "importing Jupyter notebook from args.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "from data_tools import *\n",
    "from args import parser\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9359fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac15e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder containing noises\n",
    "train_noise_dir = args.train_noise_dir     \n",
    "#folder containing clean voices\n",
    "train_voice_dir = args.train_voice_dir\n",
    "\n",
    "test_noise_dir = args.test_noise_dir     \n",
    "#folder containing clean voices\n",
    "test_voice_dir = args.test_voice_dir\n",
    "\n",
    "#path to save time series\n",
    "path_save_time_series = args.path_save_time_series\n",
    "#path to save sounds\n",
    "path_save_sound = args.path_save_sound\n",
    "#path to save spectrograms\n",
    "path_save_spectrogram = args.path_save_spectrogram  \n",
    "# Sample rate to read audio\n",
    "sample_rate = args.sample_rate\n",
    "# Minimum duration of audio files to consider\n",
    "min_duration = args.min_duration   \n",
    "#Frame length for training data\n",
    "frame_length = args.frame_length   \n",
    "# hop length for clean voice files\n",
    "hop_length_frame = args.hop_length_frame       \n",
    "# hop length for noise files\n",
    "hop_length_frame_noise = args.hop_length_frame_noise\n",
    "# How much frame to create for training\n",
    "nb_samples = args.nb_samples\n",
    "#nb of points for fft(for spectrogram computation)\n",
    "n_fft = args.n_fft  \n",
    "#hop length for fft\n",
    "hop_length_fft = args.hop_length_fft\n",
    "SNR=[-10,-5,0,5,10]\n",
    "test_out= args.audio_dir_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9247b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_noise_files = os.listdir(train_noise_dir)\n",
    "list_train_voice_files = os.listdir(train_voice_dir)\n",
    "list_test_noise_files = os.listdir(test_noise_dir)\n",
    "list_test_voice_files = os.listdir(test_voice_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "727b79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ds_store(lst):\n",
    "    #remove mac specific file if present\n",
    "    if '.DS_Store' in lst:\n",
    "        lst.remove('.DS_Store')\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2d0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove .DS_Store extension files\n",
    "list_train_noise_files = remove_ds_store(list_train_noise_files)\n",
    "list_train_voice_files = remove_ds_store(list_train_voice_files)\n",
    "list_test_noise_files = remove_ds_store(list_test_noise_files)\n",
    "list_test_voice_files = remove_ds_store(list_test_voice_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae08956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of the noise and voice files\n",
    "nb_train_voice_files = len(list_train_voice_files)\n",
    "nb_train_noise_files = len(list_train_noise_files)\n",
    "nb_test_voice_files = len(list_test_voice_files)\n",
    "nb_test_noise_files = len(list_test_noise_files)\n",
    "len_SNR= len(SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e8b6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_noise_files= sorted_nicely(list_train_noise_files)\n",
    "list_train_voice_files= sorted_nicely(list_train_voice_files)\n",
    "list_test_noise_files= sorted_nicely(list_test_noise_files)\n",
    "list_test_voice_files= sorted_nicely(list_test_voice_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6a818a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of the noise and voice files\n",
    "nb_train_voice_files = len(list_train_voice_files)\n",
    "nb_train_noise_files = len(list_train_noise_files)\n",
    "nb_test_voice_files = len(list_test_voice_files)\n",
    "nb_test_noise_files = len(list_test_noise_files)\n",
    "len_SNR= len(SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4445b69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10, 20, 10, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_train_voice_files, nb_train_noise_files, nb_test_voice_files, nb_test_noise_files, len_SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845f2c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8064, 8064, 8064)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_length, hop_length_frame, hop_length_frame_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3396caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting noise and voice from folder and convert to numpy\n",
    "noise = audio_files_to_numpy(train_noise_dir, list_train_noise_files, sample_rate, frame_length, hop_length_frame_noise, min_duration)\n",
    "voice = audio_files_to_numpy(train_voice_dir, list_train_voice_files, sample_rate, frame_length, hop_length_frame, min_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b908cf41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 8064), (12000, 8064))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voice.shape, noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8b1f8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_voice= voice[0:noise.shape[0], :]\n",
    "#test_voice= voice[10020:10080,:]\n",
    "\n",
    "train_noise= noise[0:noise.shape[0], :]\n",
    "#test_noise= noise[10020:10080, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52443a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 8064), (12000, 8064))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_voice.shape, train_noise.shape\n",
    "#test_voice.shape, test_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02119b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squared spectrogram dimensions\n",
    "dim_square_spec = int(n_fft / 2) + 1 \n",
    "dim_square_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbae214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples= train_voice.shape[0]\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce69c21",
   "metadata": {},
   "source": [
    "# Train data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d64199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR= -10 values were saved successfully\n",
      "SNR= -5 values were saved successfully\n",
      "SNR= 0 values were saved successfully\n",
      "SNR= 5 values were saved successfully\n",
      "SNR= 10 values were saved successfully\n"
     ]
    }
   ],
   "source": [
    "for i in range (len_SNR):\n",
    "    prod_voice, prod_noise, prod_noisy = blend_noise_randomly(train_voice, train_noise, nb_samples, frame_length, SNR[i])\n",
    "    \n",
    "#     voice= prod_voice.reshape(1, nb_samples*frame_length)\n",
    "#     noise= prod_noise.reshape(1, nb_samples*frame_length)\n",
    "#     noisy= prod_noisy.reshape(1, nb_samples*frame_length)\n",
    "#     sf.write('./Train/sound/male/male= '+ str(SNR[i])+'.wav', voice[0, :], samplerate= sample_rate)\n",
    "#     sf.write('./Train/sound/female/female= '+ str(SNR[i])+'.wav', noise[0, :], samplerate= sample_rate)\n",
    "#     sf.write('./Train/sound/mixed/mixed= '+ str(SNR[i])+'.wav', noisy[0, :], samplerate= sample_rate)\n",
    "    \n",
    "    \n",
    "    voice_complex_mat, voice_real, voice_imag= numpy_audio_to_matrix_spectrogram(prod_voice, dim_square_spec, n_fft, hop_length_fft)\n",
    "    del prod_voice, voice_complex_mat\n",
    "    \n",
    "    noise_complex_mat, noise_real, noise_imag= numpy_audio_to_matrix_spectrogram(prod_noise, dim_square_spec, n_fft, hop_length_fft)\n",
    "    del prod_noise, noise_complex_mat\n",
    "    \n",
    "    noisy_complex_mat, noisy_real, noisy_imag= numpy_audio_to_matrix_spectrogram(prod_noisy, dim_square_spec, n_fft, hop_length_fft)\n",
    "    del prod_noisy, noisy_complex_mat\n",
    "    \n",
    "    \n",
    "    voice_concat= np.concatenate((voice_real, voice_imag), axis=0)\n",
    "    del voice_real, voice_imag\n",
    "    \n",
    "    noise_concat= np.concatenate((noise_real, noise_imag), axis=0)\n",
    "    del noise_real, noise_imag\n",
    "    \n",
    "    noisy_concat= np.concatenate((noisy_real, noisy_imag), axis=0)\n",
    "    del noisy_real, noisy_imag\n",
    "    \n",
    "    np.save(path_save_spectrogram + 'voice_concat= '+str(SNR[i]), voice_concat)\n",
    "    np.save(path_save_spectrogram + 'noise_concat= '+str(SNR[i]), noise_concat)\n",
    "    np.save(path_save_spectrogram + 'noisy_concat= '+str(SNR[i]), noisy_concat)\n",
    "    del voice_concat, noisy_concat, noise_concat\n",
    "    print('SNR= '+str(SNR[i])+' values were saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760ddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
